@inproceedings{10.5555/3635637.3663047,
	author = {Úradník, Filip and Sychrovsk\'{y}, David and Čern\'{y}, Jakub and
	          Čern\'{y}, Martin},
	title = {{Reducing} {Optimism} {Bias} in {Incomplete} {Cooperative} {Games}},
	year = {2024},
	isbn = {9798400704864},
	publisher = {{International} {Foundation} for {Autonomous} {Agents} and {
	             Multiagent} {Systems}},
	address = {Richland, SC},
	abstract = {Cooperative game theory has diverse applications in contemporary
	            artificial intelligence, including domains like interpretable
	            machine learning, resource allocation, and collaborative
	            decision-making. However, specifying a cooperative game entails
	            assigning values to exponentially many coalitions, and obtaining
	            even a single value can be resource-intensive in practice. Yet
	            simply leaving certain coalition values undisclosed introduces
	            ambiguity regarding individual contributions to the collective
	            grand coalition. This ambiguity often leads to players holding
	            overly optimistic expectations, stemming from either inherent
	            biases or strategic considerations, frequently resulting in
	            collective claims exceeding the actual grand coalition value. In
	            this paper, we present a framework aimed at optimizing the sequence
	            for revealing coalition values, with the overarching goal of
	            efficiently closing the gap between players' expectations and
	            achievable outcomes in cooperative games. Our contributions are
	            threefold: (i) we study the individual players' optimistic
	            completions of games with missing coalition values along with the
	            arising gap, and investigate its analytical characteristics that
	            facilitate more efficient optimization; (ii) we develop methods to
	            minimize this gap over classes of games with a known prior by
	            disclosing values of additional coalitions in both offline and
	            online fashion; and (iii) we empirically demonstrate the
	            algorithms' performance in practical scenarios, together with an
	            investigation into the typical order of revealing coalition values.
	            },
	booktitle = {{Proceedings} of the 23rd {International} {Conference} on {
	             Autonomous} {Agents} and {Multiagent} {Systems}},
	pages = {1847–1855},
	numpages = {9},
	keywords = {active learning, incomplete cooperative games, shapley value,
	            superadditive set functions, value querying},
	location = {<conf-loc>, <city>Auckland</city>, <country>New Zealand</country>,
	            </conf-loc>},
	series = {AAMAS '24},
	url = {https://furadnik.github.io/projects/2024_reducing},
}

@thesis{Uradnik2024,
	author = {Filip Úradník},
	title = {{Balancing} {Space} {Complexity} and {Ambiguity} in {Superadditive} {
	         Set} {Functions}},
	address = {Prague},
	year = {2024},
	school = {Charles University, Faculty of Mathematics {and} Physics, Department
	          of Applied Mathematics},
	type = {Bachelor's thesis},
	url = {https://furadnik.github.io/projects/2024_bakalarka},
}

@inproceedings{aamas25,
	author = {Úradník\textsuperscript{*}, Filip and Wang\textsuperscript{*},
	          Amanda and Gao, Jie},
	title = {{Maximizing} {Truth} {Learning} in a {Social} {Network} is NP-hard},
	year = {2025},
	isbn = {9798400714269},
	publisher = {International Foundation for Autonomous Agents and Multiagent
	             Systems},
	address = {Richland, SC},
	abstract = { Sequential learning models situations where agents predict a
	            ground truth in sequence, by using their private, noisy
	            measurements, and the predictions of agents who came earlier in the
	            sequence. We study sequential learning in a social network, where
	            agents only see the actions of the previous agents in their own
	            neighborhood. The fraction of agents who predict the ground truth
	            correctly depends heavily on both the network topology and the
	            ordering in which the predictions are made. A natural question is
	            to find an ordering, with a given network, to maximize the
	            (expected) number of agents who predict the ground truth correctly.
	            In this paper, we show that it is in fact NP-hard to answer this
	            question for a general network, with both the Bayesian learning
	            model and a simple majority rule model. Finally, we show that even
	            approximating the answer is hard.},
	booktitle = {Proceedings of the 24th International Conference on Autonomous
	             Agents and Multiagent Systems},
	pages = {2078–2086},
	numpages = {9},
	keywords = {active learning, incomplete cooperative games, shapley value,
	            superadditive set functions, value querying},
	location = {<conf-loc>, <city>Detroit, MI</city>, <country>United
	            States</country>, </conf-loc>},
	series = {AAMAS '25},
	url = {https://furadnik.github.io/projects/2025_truth_learning},
}


